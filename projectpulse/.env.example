# GitHub API Token (recommended for higher rate limits)
# Create at: https://github.com/settings/tokens
GITHUB_TOKEN=your_github_personal_access_token

# Ollama Configuration (local AI)
# Make sure Ollama is running: ollama serve
# Recommended models: qwen2.5:14b, qwen3-coder:30b (requires 32GB RAM)
# Pull model: ollama pull qwen2.5:14b
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:14b

# Server port
PORT=3002

# Client URL (for CORS)
CLIENT_URL=http://localhost:5173
